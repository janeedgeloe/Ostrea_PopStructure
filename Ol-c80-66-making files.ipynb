{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering .vcf file from ipyrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the secondary filtering I do with a .vcf directly from ipyrad. I use this notebook to:  \n",
    "1) remove weird individuals based on PCA analysis,  \n",
    "2) filter out individuals with greater than a certain threshold of missing data,  \n",
    "3) filter out loci missing in a certain percentage of samples (note: ipyrad does this on a locus basis, but with indels and Ns there could still be sites that are missing in a lot of samples),  \n",
    "4) filter for a certain minor allele frequency  \n",
    "5) filter out loci with excess heterozygosity within populations based on Hardy-Weinberg equilibrium \\*  \n",
    "6) filter out loci significantly out of H-W equilibrium within populations  \n",
    "7) filter for only biallelic SNPs  \n",
    "8) use python code to select 1 SNP per GBS locus  \n",
    "\n",
    "\n",
    "\\*Note: I set the *max_shared_Hs_locus* parameter in ipyrad to 1.0 so it does not filter for excess heterozygotes across samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/28/17\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "date \"+%D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ksilliman/Projects/Phylo_Ostrea/c80-denovo/Making_Files\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ksilliman/Projects/Phylo_Ostrea/c80-denovo/Making_Files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use *bcftools* to rename a sample who's barcode file was incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA2_8 OR3_1\r\n",
      "OR3_1 CA2_8\r\n",
      "OR7_5 CA7_5\r\n"
     ]
    }
   ],
   "source": [
    "%cat OR_CAfix.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "bcftools reheader -s OR_CAfix.txt -o cp-OL-s7filter-s67-c80-66.vcf ../OL-s7filter-s67-c80-66_outfiles/OL-s7filter-s67-c80-66.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing weird individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf cp-OL-s7filter-s67-c80-66.vcf\n",
      "\t--recode-INFO-all\n",
      "\t--min-alleles 2\n",
      "\t--out OL-c80-66-s67\n",
      "\t--recode\n",
      "\t--remove-indv CA5_15b\n",
      "\t--remove-indv OR2_11\n",
      "\t--remove-indv WA10_11\n",
      "\n",
      "Excluding individuals in 'exclude' list\n",
      "After filtering, kept 190 out of 193 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 102749 out of a possible 102749 Sites\n",
      "Run Time = 15.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf cp-OL-s7filter-s67-c80-66.vcf --recode --recode-INFO-all --remove-indv \\\n",
    "CA5_15b --remove-indv WA10_11 --remove-indv OR2_11 --min-alleles 2 --out OL-c80-66-s67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a file with the percent missingness for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf OL-c80-66-s67.recode.vcf\n",
      "\t--missing-indv\n",
      "\t--out OL-c80-66-s67\n",
      "\n",
      "After filtering, kept 190 out of 190 Individuals\n",
      "Outputting Individual Missingness\n",
      "After filtering, kept 102749 out of a possible 102749 Sites\n",
      "Run Time = 2.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf OL-c80-66-s67.recode.vcf --missing-indv --out OL-c80-66-s67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDV\tN_DATA\tN_GENOTYPES_FILTERED\tN_MISS\tF_MISS\n",
      "BC1_1\t102749\t0\t57941\t0.563908\n",
      "BC1_10\t102749\t0\t9766\t0.0950472\n",
      "BC1_11\t102749\t0\t60349\t0.587344\n",
      "BC1_12\t102749\t0\t50174\t0.488316\n",
      "BC1_19\t102749\t0\t66593\t0.648113\n",
      "BC1_2\t102749\t0\t78917\t0.768056\n",
      "BC1_20\t102749\t0\t13687\t0.133208\n",
      "BC1_22\t102749\t0\t5617\t0.0546672\n",
      "BC1_4\t102749\t0\t15596\t0.151787\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "head OL-c80-66-s67.imiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('ksil91', 'ycvvzZQxVMU8Sg9wVQBH')\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ksil91/136.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imiss = np.genfromtxt('OL-c80-66-s67.imiss', names=True,dtype=None)\n",
    "data = [\n",
    "    go.Histogram(\n",
    "        x=imiss[[\"F_MISS\"]],autobinx = False,\n",
    "        xbins=dict(\n",
    "            start=0,\n",
    "            end=1,\n",
    "            size=0.05\n",
    "        )\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Proportion missing data, ',bargap=0.1)\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals missing data at fewer than 62% of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BC1_1', 'BC1_10', 'BC1_11', 'BC1_12', 'BC1_20', 'BC1_22', 'BC1_4',\n",
       "       'BC1_7', 'BC1_8', 'BC1_9', 'BC2_10', 'BC2_11', 'BC2_12', 'BC2_13',\n",
       "       'BC2_16', 'BC2_17', 'BC2_18', 'BC2_3', 'BC2_6', 'BC2_7', 'BC2_9',\n",
       "       'BC3_1', 'BC3_16', 'BC3_17', 'BC3_18', 'BC3_20', 'BC3_3', 'BC3_9',\n",
       "       'BC4_12', 'BC4_13', 'BC4_15', 'BC4_19', 'BC4_2', 'BC4_3', 'BC4_6',\n",
       "       'BC4_7', 'BC4_9', 'CA1_15', 'CA1_16', 'CA1_19', 'CA1_2', 'CA1_22',\n",
       "       'CA1_4', 'CA1_5', 'CA1_9', 'CA2_10', 'CA2_12', 'OR3_1', 'CA3_4',\n",
       "       'CA3_6', 'CA3_7', 'CA3_8', 'CA4_1', 'CA4_16', 'CA4_2', 'CA4_20',\n",
       "       'CA4_9', 'CA5_10', 'CA5_11', 'CA5_13', 'CA5_14', 'CA5_15a', 'CA5_7',\n",
       "       'CA6_10', 'CA6_11', 'CA6_12', 'CA6_13', 'CA6_14', 'CA6_16',\n",
       "       'CA6_18', 'CA6_2', 'CA7_10', 'CA7_11', 'CA7_12', 'CA7_13', 'CA7_15',\n",
       "       'CA7_2', 'CA7_7', 'CA7_8', 'CA7_9', 'OR1_1', 'OR1_11', 'OR1_2',\n",
       "       'OR1_4', 'OR1_5', 'OR1_6', 'OR1_7', 'OR2_1', 'OR2_10', 'OR2_2',\n",
       "       'OR2_20', 'OR2_9', 'CA2_8', 'OR3_15', 'OR3_17', 'OR3_18', 'OR3_20',\n",
       "       'OR3_5', 'OR3_7', 'CA7_5', 'WA10_1', 'WA10_10', 'WA10_12',\n",
       "       'WA10_14', 'WA10_15', 'WA10_16', 'WA10_18', 'WA10_2', 'WA10_5',\n",
       "       'WA11_10', 'WA11_13', 'WA11_17', 'WA11_20', 'WA11_22', 'WA11_3',\n",
       "       'WA11_4', 'WA11_9', 'WA12_11', 'WA12_14', 'WA12_2', 'WA12_22',\n",
       "       'WA12_3', 'WA13_13', 'WA13_15', 'WA13_16', 'WA13_19', 'WA13_2',\n",
       "       'WA13_3', 'WA1_1', 'WA1_11', 'WA1_14', 'WA1_3', 'WA1_8', 'WA9_10',\n",
       "       'WA9_2', 'WA9_5', 'WA9_8'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imissDF = pandas.DataFrame(imiss)\n",
    "imissDF[imissDF.F_MISS < 0.62].INDV.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imissDF[imissDF.F_MISS < 0.62].INDV.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write file of individuals with missing data at greater than 62% of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imissDF[imissDF.F_MISS > 0.62].INDV.to_csv(\"OL-c80-66-s67_imiss62.txt\",sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use vcftools to remove individuals with greater than 62% missingness. ALso filter for polymorphic loci, loci missing in < 50% of individuals, and a minor allele frequency of 2.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf OL-c80-66-s67.recode.vcf\n",
      "\t--remove OL-c80-66-s67_imiss62.txt\n",
      "\t--recode-INFO-all\n",
      "\t--maf 0.025\n",
      "\t--min-alleles 2\n",
      "\t--max-missing 0.5\n",
      "\t--out OL-c80-66-s67-m50x62-maf025\n",
      "\t--recode\n",
      "\n",
      "Excluding individuals in 'exclude' list\n",
      "After filtering, kept 137 out of 190 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 34565 out of a possible 102749 Sites\n",
      "Run Time = 6.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf OL-c80-66-s67.recode.vcf --recode --recode-INFO-all --remove \\\n",
    "OL-c80-66-s67_imiss62.txt --min-alleles 2 --max-missing 0.5 --maf 0.025 --out OL-c80-66-s67-m50x62-maf025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use vcftools to remove individuals with greater than 62% missingness. ALso filter for polymorphic loci, loci missing in < 70% of individuals, and a minor allele frequency of 2.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf OL-c80-66-s67.recode.vcf\n",
      "\t--remove OL-c80-66-s67_imiss62.txt\n",
      "\t--recode-INFO-all\n",
      "\t--maf 0.025\n",
      "\t--min-alleles 2\n",
      "\t--max-missing 0.7\n",
      "\t--out OL-c80-66-s67-m70x62-maf025\n",
      "\t--recode\n",
      "\n",
      "Excluding individuals in 'exclude' list\n",
      "After filtering, kept 137 out of 190 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 20910 out of a possible 102749 Sites\n",
      "Run Time = 5.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf OL-c80-66-s67.recode.vcf --recode --recode-INFO-all --remove \\\n",
    "OL-c80-66-s67_imiss62.txt --min-alleles 2 --max-missing 0.70 --maf 0.025 --out OL-c80-66-s67-m70x62-maf025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write files with the sample name and either population (.pop) or sampling location (.loc). These are used for the heterozygosity filtering downstream and to convert the .vcf file to a .str file in PGD Spider. It is dependent on the samples having their population as the first part of their name, separated by an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IN = open(\"OL-c80-66-s67.imiss\",\"r\")\n",
    "OUT = open(\"OL-c80-66-s67.pop\",\"w\")\n",
    "pop_dict = {'CA2':'CA23','CA3':'CA23','WA1':'WA19','WA9':'WA19'}\n",
    "IN.next()\n",
    "for line in IN:\n",
    "    name = line.split()[0]\n",
    "    pop = name.split(\"_\")[0]\n",
    "    if pop in pop_dict.keys():\n",
    "        pop = pop_dict[pop]\n",
    "    OUT.write(name+\"\\t\"+pop+\"\\n\")\n",
    "    \n",
    "IN.close()\n",
    "OUT.close()\n",
    "\n",
    "IN = open(\"OL-c80-66-s67.imiss\",\"r\")\n",
    "OUT = open(\"OL-c80-66-s67.loc\",\"w\")\n",
    "IN.next()\n",
    "for line in IN:\n",
    "    name = line.split()[0]\n",
    "    pop = name.split(\"_\")[0]\n",
    "    OUT.write(name+\"\\t\"+pop+\"\\n\")\n",
    "    \n",
    "IN.close()\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC1_1\tBC1\n",
      "BC1_10\tBC1\n",
      "BC1_11\tBC1\n",
      "BC1_12\tBC1\n",
      "BC1_19\tBC1\n",
      "BC1_2\tBC1\n",
      "BC1_20\tBC1\n",
      "BC1_22\tBC1\n",
      "BC1_4\tBC1\n",
      "BC1_7\tBC1\n",
      "BC1_8\tBC1\n",
      "BC1_9\tBC1\n",
      "BC2_1\tBC2\n",
      "BC2_10\tBC2\n",
      "BC2_11\tBC2\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "head -n 15 OL-c80-66-s67.pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering loci by excess heterozygosity and departures from Hardy-Weinberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I filter out loci with excess heterozygosity in at least 2 populations based on Hardy-Weinberg equilibrium and a p-value cutoff of 0.1. It takes a .vcf file and the .pop file just created as input. This uses a slightly modified script from [Jon Puritz's Github](https://github.com/jpuritz/dDocent/blob/master/scripts/filter_hwe_by_pop.pl), written by Chris Hollenbeck. My modified script is in my Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing population: BC1 (12 inds)\n",
      "Processing population: BC2 (13 inds)\n",
      "Processing population: BC3 (10 inds)\n",
      "Processing population: BC4 (12 inds)\n",
      "Processing population: CA1 (11 inds)\n",
      "Processing population: CA23 (12 inds)\n",
      "Processing population: CA4 (9 inds)\n",
      "Processing population: CA5 (8 inds)\n",
      "Processing population: CA6 (9 inds)\n",
      "Processing population: CA7 (10 inds)\n",
      "Processing population: OR1 (12 inds)\n",
      "Processing population: OR2 (10 inds)\n",
      "Processing population: OR3 (10 inds)\n",
      "Processing population: WA10 (10 inds)\n",
      "Processing population: WA11 (9 inds)\n",
      "Processing population: WA12 (9 inds)\n",
      "Processing population: WA13 (10 inds)\n",
      "Processing population: WA19 (14 inds)\n",
      "Outputting results of HWE test for filtered loci to 'filtered.hetexc'\n",
      "Kept 34540 of a possible 34565 loci (filtered 25 loci)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir het_m50x62_maf025\n",
    "#Filtering out loci that have excess heterozygosity in at least 2 regions with a p-value cutoff of 0.1\n",
    "../../Methods/Scripts/filter_hetexc_by_pop.pl -v OL-c80-66-s67-m50x62-maf025.recode.vcf -p OL-c80-66-s67.pop -h 0.1 -c 0.12 -o OL-c80-66-s67-m50x62-maf025-hetP\n",
    "mv *.hwe het_m50x62_maf025/\n",
    "mv *.hetexc het_m50x62_maf025/\n",
    "rm *.inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing population: BC1 (12 inds)\n",
      "Processing population: BC2 (13 inds)\n",
      "Processing population: BC3 (10 inds)\n",
      "Processing population: BC4 (12 inds)\n",
      "Processing population: CA1 (11 inds)\n",
      "Processing population: CA23 (12 inds)\n",
      "Processing population: CA4 (9 inds)\n",
      "Processing population: CA5 (8 inds)\n",
      "Processing population: CA6 (9 inds)\n",
      "Processing population: CA7 (10 inds)\n",
      "Processing population: OR1 (12 inds)\n",
      "Processing population: OR2 (10 inds)\n",
      "Processing population: OR3 (10 inds)\n",
      "Processing population: WA10 (10 inds)\n",
      "Processing population: WA11 (9 inds)\n",
      "Processing population: WA12 (9 inds)\n",
      "Processing population: WA13 (10 inds)\n",
      "Processing population: WA19 (14 inds)\n",
      "Outputting results of HWE test for filtered loci to 'filtered.hetexc'\n",
      "Kept 20892 of a possible 20910 loci (filtered 18 loci)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir het_m70x62_maf025\n",
    "#Filtering out loci that have excess heterozygosity in at least 2 regions with a p-value cutoff of 0.1\n",
    "../../Methods/Scripts/filter_hetexc_by_pop.pl -v OL-c80-66-s67-m70x62-maf025.recode.vcf -p OL-c80-66-s67.pop \\\n",
    "-h 0.1 -c 0.12 -o OL-c80-66-s67-m70x62-maf025-hetP\n",
    "mv *.hwe het_m70x62_maf025/\n",
    "mv *.hetexc het_m70x62_maf025/\n",
    "rm *.inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script only filters on a site-by-site basis. In order to throw out any loci that had a SNP with excess heterozygosity (as these may be paralogs), I make a file with the locus ids to then submit to vcftools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maf 0.025, m50-x62: 8\n"
     ]
    }
   ],
   "source": [
    "#Make files of bad loci (that have at least one site with excess heterozygotes) to copy/paste in vcftools. \n",
    "IN = open('het_m50x62_maf025/exclude.hetexc', \"r\")\n",
    "OUT = open('het_m50x62_maf025/badchrom.txt', \"w\")\n",
    "exset = set()\n",
    "for line in IN:\n",
    "    chrom = line.split()[0]\n",
    "    if chrom not in exset:\n",
    "        exset.add(chrom)\n",
    "        OUT.write(\" --not-chr \"+str(chrom))\n",
    "OUT.close()\n",
    "IN.close()\n",
    "print \"Maf 0.025, m50-x62: \"+str(len(exset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maf025 4, m70-x65: 5\n"
     ]
    }
   ],
   "source": [
    "#Make files of bad loci (that have at least one site with excess heterozygotes) to copy/paste in vcftools. \n",
    "IN = open('het_m70x62_maf025/exclude.hetexc', \"r\")\n",
    "OUT = open('het_m70x62_maf025/badchrom.txt', \"w\")\n",
    "exset = set()\n",
    "for line in IN:\n",
    "    chrom = line.split()[0]\n",
    "    if chrom not in exset:\n",
    "        exset.add(chrom)\n",
    "        OUT.write(\" --not-chr \"+str(chrom))\n",
    "OUT.close()\n",
    "IN.close()\n",
    "print \"Maf025 4, m70-x65: \"+str(len(exset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vcftools won't take a file of locus names to remove (which is annoying), so I copy and paste the locus names with a --not-chr call into vcftools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --not-chr locus_286414 --not-chr locus_22966 --not-chr locus_290641 --not-chr locus_371902 --not-chr locus_163220 --not-chr locus_343612 --not-chr locus_20481 --not-chr locus_296426"
     ]
    }
   ],
   "source": [
    "%cat het_m50x62_maf025/badchrom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf OL-c80-66-s67-m50x62-maf025-hetP.recode.vcf\n",
      "\t--not-chr locus_163220\n",
      "\t--not-chr locus_20481\n",
      "\t--not-chr locus_22966\n",
      "\t--not-chr locus_286414\n",
      "\t--not-chr locus_290641\n",
      "\t--not-chr locus_296426\n",
      "\t--not-chr locus_343612\n",
      "\t--not-chr locus_371902\n",
      "\t--recode-INFO-all\n",
      "\t--max-alleles 2\n",
      "\t--min-alleles 2\n",
      "\t--out OL-c80-66-s67-m50x62-maf025-hetPbi\n",
      "\t--recode\n",
      "\n",
      "After filtering, kept 137 out of 137 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 34117 out of a possible 34540 Sites\n",
      "Run Time = 4.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf OL-c80-66-s67-m50x62-maf025-hetP.recode.vcf --recode --recode-INFO-all  --not-chr locus_290641 --not-chr locus_286414 --not-chr locus_343612 --not-chr locus_371902 --not-chr locus_20481 --not-chr locus_22966 --not-chr locus_163220 --not-chr locus_296426 \\\n",
    "--max-alleles 2 --min-alleles 2 --out OL-c80-66-s67-m50x62-maf025-hetPbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --not-chr locus_371902 --not-chr locus_20481 --not-chr locus_286414 --not-chr locus_343612 --not-chr locus_163220"
     ]
    }
   ],
   "source": [
    "%cat het_m70x62_maf025/badchrom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.15\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--vcf OL-c80-66-s67-m70x62-maf025-hetP.recode.vcf\n",
      "\t--not-chr locus_163220\n",
      "\t--not-chr locus_20481\n",
      "\t--not-chr locus_286414\n",
      "\t--not-chr locus_343612\n",
      "\t--not-chr locus_371902\n",
      "\t--recode-INFO-all\n",
      "\t--max-alleles 2\n",
      "\t--min-alleles 2\n",
      "\t--out OL-c80-66-s67-m70x62-maf025-hetPbi\n",
      "\t--recode\n",
      "\n",
      "After filtering, kept 137 out of 137 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 20660 out of a possible 20892 Sites\n",
      "Run Time = 3.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "vcftools --vcf OL-c80-66-s67-m70x62-maf025-hetP.recode.vcf --recode --recode-INFO-all  --not-chr locus_371902 --not-chr locus_20481 --not-chr locus_286414 --not-chr locus_343612 --not-chr locus_163220 \\\n",
    "--max-alleles 2 --min-alleles 2 --out OL-c80-66-s67-m70x62-maf025-hetPbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter loci with a by departure from HW in at least 2 populations and a p-value cutoff of 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing population: BC1 (12 inds)\n",
      "Processing population: BC2 (13 inds)\n",
      "Processing population: BC3 (10 inds)\n",
      "Processing population: BC4 (12 inds)\n",
      "Processing population: CA1 (11 inds)\n",
      "Processing population: CA23 (12 inds)\n",
      "Processing population: CA4 (9 inds)\n",
      "Processing population: CA5 (8 inds)\n",
      "Processing population: CA6 (9 inds)\n",
      "Processing population: CA7 (10 inds)\n",
      "Processing population: OR1 (12 inds)\n",
      "Processing population: OR2 (10 inds)\n",
      "Processing population: OR3 (10 inds)\n",
      "Processing population: WA10 (10 inds)\n",
      "Processing population: WA11 (9 inds)\n",
      "Processing population: WA12 (9 inds)\n",
      "Processing population: WA13 (10 inds)\n",
      "Processing population: WA19 (14 inds)\n",
      "Outputting results of HWE test for filtered loci to 'filtered.hwe'\n",
      "Kept 34072 of a possible 34117 loci (filtered 45 loci)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir hwe_m50x62_maf025\n",
    "#Filtering out loci that have excess heterozygosity in at least 2 populations with a p-value cutoff of 0.025\n",
    "../../Methods/Scripts/filter_hwe_by_pop.pl -v OL-c80-66-s67-m50x62-maf025-hetPbi.recode.vcf -p OL-c80-66-s67.pop -h 0.025 -c 0.12 -o OL-c80-66-s67-m50x62-maf025-hetPhwPbi\n",
    "mv *.hwe hwe_m50x62_maf025/\n",
    "rm *.inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing population: BC1 (12 inds)\n",
      "Processing population: BC2 (13 inds)\n",
      "Processing population: BC3 (10 inds)\n",
      "Processing population: BC4 (12 inds)\n",
      "Processing population: CA1 (11 inds)\n",
      "Processing population: CA23 (12 inds)\n",
      "Processing population: CA4 (9 inds)\n",
      "Processing population: CA5 (8 inds)\n",
      "Processing population: CA6 (9 inds)\n",
      "Processing population: CA7 (10 inds)\n",
      "Processing population: OR1 (12 inds)\n",
      "Processing population: OR2 (10 inds)\n",
      "Processing population: OR3 (10 inds)\n",
      "Processing population: WA10 (10 inds)\n",
      "Processing population: WA11 (9 inds)\n",
      "Processing population: WA12 (9 inds)\n",
      "Processing population: WA13 (10 inds)\n",
      "Processing population: WA19 (14 inds)\n",
      "Outputting results of HWE test for filtered loci to 'filtered.hwe'\n",
      "Kept 20627 of a possible 20660 loci (filtered 33 loci)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir hwe_m70x62_maf025\n",
    "#Filtering out loci that have excess heterozygosity in at least 2 populations with a p-value cutoff of 0.05\n",
    "../../Methods/Scripts/filter_hwe_by_pop.pl -v OL-c80-66-s67-m70x62-maf025-hetPbi.recode.vcf -p OL-c80-66-s67.pop -h 0.025 -c 0.12 -o OL-c80-66-s67-m70x62-maf025-hetPhwPbi\n",
    "mv *.hwe hwe_m70x62_maf025/\n",
    "rm *.inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset one SNP per GBS locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Code to subset one SNP per GBS locus from a VCF file. Chooses the SNP\n",
    "## with the highest sample coverage. If there is a tie, chooses the 1st SNP in the loci. (may change to random)\n",
    "## May be specific to VCF format output from ipyrad.\n",
    "## This is also in script format in Github as subsetSNPs.py\n",
    "\n",
    "def subsetSNPs(inputfile,outputfile):\n",
    "    import linecache\n",
    "    locidict = {}\n",
    "    lineNum = []\n",
    "    IN = open(inputfile, \"r\")\n",
    "    OUT = open(outputfile, \"w\")\n",
    "\n",
    "    n = 1\n",
    "    for line in IN:\n",
    "        if \"#\" not in line:\n",
    "            linelist = line.split()\n",
    "            loci = linelist[0]\n",
    "            #Column 7 is INFO column of VCF file\n",
    "            NS = float(linelist[7].split(\";\")[0].split(\"=\")[1])\n",
    "            if loci not in locidict.keys():\n",
    "                locidict[loci] = [NS,n]\n",
    "            else:\n",
    "                if locidict[loci][0] < NS:\n",
    "                    locidict[loci] = [NS,n]\n",
    "        else:\n",
    "            OUT.write(line)\n",
    "        n += 1\n",
    "    IN.close()\n",
    "    print(\"Total SNPS: \"+str(n)+\"\\nUnlinked SNPs: \"+str(len(locidict.keys())))\n",
    "\n",
    "    for locus in sorted(locidict.keys()):\n",
    "        line = linecache.getline(inputfile, locidict[locus][1])\n",
    "        OUT.write(line)\n",
    "    OUT.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPS: 34084\n",
      "Unlinked SNPs: 13834\n"
     ]
    }
   ],
   "source": [
    "infile = \"OL-c80-66-s67-m50x62-maf025-hetPhwPbi.recode.vcf\"\n",
    "outfile = \"Inputs/OL-c80-66-s67-m50x62-maf025-u.vcf\"\n",
    "subsetSNPs(infile,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPS: 20639\n",
      "Unlinked SNPs: 9170\n"
     ]
    }
   ],
   "source": [
    "infile = \"OL-c80-66-s67-m70x62-maf025-hetPhwPbi.recode.vcf\"\n",
    "outfile = \"Inputs/OL-c80-66-s67-m70x62-maf025-u.vcf\"\n",
    "subsetSNPs(infile,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "These .vcf files are then converted to Structure format files using PGD Spider, in order to load into Adegenet in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
